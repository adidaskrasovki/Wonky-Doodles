{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cba24773",
   "metadata": {},
   "source": [
    "# Hello, Welcome!\n",
    "\n",
    "This Notebook uses Machine Learning / PyTorch for recognizing handwritten numbers, but can easily be modfied for other class recognition purposes. You may use this as a kickstarter or skeleton for your own purposes, or steal this entirely. Just call me out when you do so please.  \n",
    "\n",
    "This notebook is based on the Pytorch tutorial by Patrick Loeber:  \n",
    "https://www.youtube.com/watch?v=c36lUUr864M\n",
    "\n",
    "I'm using the Dataset from this link:  \n",
    "https://www.kaggle.com/datasets/jcprogjava/handwritten-digits-dataset-not-in-mnist\n",
    "\n",
    "### Known Issues:\n",
    "- Output flickers for Visual Studio. However, this seems to be an issue with VS and might be impossible to fix from my side.\n",
    "\n",
    "### If you are using Windows:  \n",
    "Copy/Paste the line below into the Windows cmd console if tensorboard won't start or is giving you a hard time in general.\n",
    "Kills the tensorboard process, which can be really tough and persists to run even after restart of your machine.\n",
    "\n",
    "    del /q %TMP%\\.tensorboard-info\\*\n",
    "\n",
    "Also, Microsoft Defender is slowing down Dataloading significantly.\n",
    "\n",
    "### If you are using Tensorboard:  \n",
    "Tensorboard creates new folders in your working directory. Make sure you have writing permissions or turn tensorboard off by setting\n",
    "\n",
    "    tb_analytics = False. \n",
    "\n",
    "Don't forget to delete everything in the folder once you're done here!\n",
    "\n",
    "### If you are using Jupyter Notebooks:  \n",
    "Use this link to start a tensorboard session in your browser:  \n",
    "http://localhost:6006/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e29e1f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "### ALL THE IMPORTS ###\n",
    "#######################\n",
    "\n",
    "# PyTorch imports\n",
    "import torch as tc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, Subset\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.multiprocessing import Pool\n",
    "\n",
    "import torchvision as tv\n",
    "import torchvision.io as io\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PIL Imports\n",
    "from PIL import Image\n",
    "from PIL import ImageStat\n",
    "from PIL import ImageOps\n",
    "from PIL import ImageShow\n",
    "from PIL import ImageFilter\n",
    "\n",
    "# Standard pkg imports\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from threading import Thread as Thread\n",
    "from threading import Event as Event\n",
    "import re\n",
    "\n",
    "# Tensorboard imports\n",
    "import tensorboard\n",
    "from tensorboard import notebook\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "logdir =  './runs/'                 # dir in which to save run data\n",
    "writer = SummaryWriter(logdir)      # init tensorboard data writer\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs\n",
    "dir_counter = 0                     # counter for setting up tensorboard folders; different training runs will be saved in different folders\n",
    "\n",
    "clear_output()\n",
    "\n",
    "# CUDA\n",
    "if tc.cuda.is_available():\n",
    "    device = tc.device(\"cuda\")\n",
    "else:\n",
    "    device = tc.device(\"cpu\")\n",
    "\n",
    "print(f\"CUDA is available: {tc.cuda.is_available()}\")\n",
    "\n",
    "import RecognitionNN_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b92c995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PREPARE DATA ####\n",
    "###### - 0.1 - #######\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "        # Adapter from your Dataset to Dataloader and thus specific for each Dataset.\n",
    "        # Microsoft Defender might slow things down here significantly. Take a look at your task manager.\n",
    "\n",
    "        datapath = \".\\quickdraw_dataset_png\"\n",
    "        train_test_ratio = 0.80                                     # define ratio of train/total samples\n",
    "\n",
    "\n",
    "        ID_list = []\n",
    "        ID = 0\n",
    "        for dir in os.listdir(datapath):\n",
    "                with open(f\"{datapath}/{dir}/address_list.txt\") as g:\n",
    "                        for line in g:\n",
    "                                ID_list.append(ID)\n",
    "                                ID += 1\n",
    "\n",
    "        quickdraw_dataset = utils.Quickdraw_Dataset(ID_list, datapath, \"label_list.txt\")\n",
    "        quickdraw_trn, quickdraw_tst = quickdraw_dataset.split_trn_tst(train_test_ratio)\n",
    "        \n",
    "        del ID\n",
    "        del ID_list\n",
    "        del quickdraw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c37846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "##### DATALOADER #####\n",
    "###### - 0.2 - #######\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Shove both training and test lists into the dataloader.\n",
    "\n",
    "    batch_size = 32                                                 # define batch_size\n",
    "\n",
    "    batches_trn = DataLoader(dataset = quickdraw_trn,                    # samples input\n",
    "                        batch_size = batch_size,\n",
    "                        shuffle = False,                           # no need to shuffle, we already did that\n",
    "                        num_workers = 6,                           # strongly recommended to keep = 0\n",
    "                        persistent_workers = False,\n",
    "                        pin_memory = True)                         # prevent loading into memory after every epoch\n",
    "\n",
    "    batches_tst = DataLoader(dataset = quickdraw_tst,\n",
    "                        batch_size = batch_size,\n",
    "                        shuffle = False,\n",
    "                        num_workers = 6,\n",
    "                        persistent_workers = False,\n",
    "                        pin_memory = True)\n",
    "\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569b82f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\cempos python scripts\\machine learning\\Doodles\\RecognitionNN_utils.py:122: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return ((tc.tensor(input_dim) - tc.tensor(kernel_size) + 2*tc.tensor(padding)) / (tc.tensor(stride))) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "##### DEFINE MODEL ####\n",
    "######## - 1 - ########\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    model = utils.ConvNN(quickdraw_trn.__getitem__(0)[0].shape,\n",
    "                fc1_dim = int(32768/2/2),\n",
    "                fc2_dim = int(16384/2/2),\n",
    "                output_dim = len(quickdraw_trn.label_list)\n",
    "                )\n",
    "\n",
    "    # Optional Block for loading in a model and/or model-state from disk\n",
    "    # filepath = './'\n",
    "    # filename = \"Tutorial_CNN.pth\"\n",
    "    # model = tc.load(f\"{filepath}{filename}\").to(device)\n",
    "    # model.load_state_dict(tc.load(f\"{filepath}{filename}_state_dict\"))\n",
    "\n",
    "    ###### LOSS/COST ######\n",
    "    ###### OPTIMIZER ######\n",
    "    ###### SCHEDULER ######\n",
    "    ######## - 2 - ########\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = tc.optim.Adam(model.parameters(),\n",
    "                            lr = .001)                                     # define initial learning rate\n",
    "\n",
    "    step_lr_scheduler = lr_scheduler.StepLR(optimizer,\n",
    "                                            step_size = 1,                  # diminish learning rate every n-th epoch...\n",
    "                                            gamma = .1)                     # ...by this diminishing factor\n",
    "\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa328f92",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.82 GiB (GPU 0; 6.00 GiB total capacity; 10.49 GiB already allocated; 0 bytes free; 10.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m     dir_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39m# Training Loop. \u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# Note that loading the batches into memory might take a few minutes. Take a look at your task manager.\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m model_trn \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mtraining_loop(n_epochs \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,                             \u001b[39m# See func definition for input details\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m                         print_fps \u001b[39m=\u001b[39;49m \u001b[39m5.\u001b[39;49m,\n\u001b[0;32m     20\u001b[0m                         model \u001b[39m=\u001b[39;49m model,\n\u001b[0;32m     21\u001b[0m                         batches_trn \u001b[39m=\u001b[39;49m batches_trn,\n\u001b[0;32m     22\u001b[0m                         criterion \u001b[39m=\u001b[39;49m criterion,\n\u001b[0;32m     23\u001b[0m                         optimizer \u001b[39m=\u001b[39;49m optimizer,\n\u001b[0;32m     24\u001b[0m                         scheduler \u001b[39m=\u001b[39;49m step_lr_scheduler,\n\u001b[0;32m     25\u001b[0m                         tb_analytics \u001b[39m=\u001b[39;49m tb_analytics)\n",
      "File \u001b[1;32md:\\cempos python scripts\\machine learning\\Doodles\\RecognitionNN_utils.py:276\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(model, batches_trn, criterion, optimizer, scheduler, n_epochs, tb_analytics, print_fps)\u001b[0m\n\u001b[0;32m    274\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()                                                   \u001b[39m# reset gradient calc\u001b[39;00m\n\u001b[0;32m    275\u001b[0m cost \u001b[39m=\u001b[39m criterion(output_prd, output_tru)                                \u001b[39m# calc cost value\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m cost\u001b[39m.\u001b[39;49mbackward()                                                         \u001b[39m# backward propagation\u001b[39;00m\n\u001b[0;32m    277\u001b[0m optimizer\u001b[39m.\u001b[39mstep()                                                        \u001b[39m# apply optimizer\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[39m# Output Block\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MachineLearning\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.82 GiB (GPU 0; 6.00 GiB total capacity; 10.49 GiB already allocated; 0 bytes free; 10.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "###### TRAINING #######\n",
    "######## - 3 - ########\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Optional Block for using tensorboard\n",
    "    tb_analytics = True\n",
    "\n",
    "\n",
    "    if tb_analytics:\n",
    "        logdir = f\"./runs/{dir_counter}/\"\n",
    "        writer = SummaryWriter(logdir)\n",
    "        utils.tb_write_model(model, quickdraw_trn)\n",
    "        dir_counter += 1\n",
    "\n",
    "\n",
    "    # Training Loop. \n",
    "    # Note that loading the batches into memory might take a few minutes. Take a look at your task manager.\n",
    "    model_trn = utils.training_loop(n_epochs = 2,                             # See func definition for input details\n",
    "                            print_fps = 5.,\n",
    "                            model = model,\n",
    "                            batches_trn = batches_trn,\n",
    "                            criterion = criterion,\n",
    "                            optimizer = optimizer,\n",
    "                            scheduler = step_lr_scheduler,\n",
    "                            tb_analytics = tb_analytics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### TESTING #######\n",
    "######## - 4 - ########\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Testing Loop.\n",
    "    # Again, loading batches into memory may take a few minutes. Stay strong.\n",
    "\n",
    "    # device = tc.device(\"cpu\")                                           # optional, but runs faster on cpu for some reason\n",
    "    accuracy = utils.validation_loop(print_fps = 5.,                          # See func definition for input details\n",
    "                            print_miss = False,\n",
    "                            model = model_trn.to(device),\n",
    "                            batches_tst = batches_tst)\n",
    "\n",
    "    # if tc.cuda.is_available():                                          # change back to gpu\n",
    "    #     device = tc.device(\"cuda\")\n",
    "    # else:\n",
    "    #     device = tc.device(\"cpu\")\n",
    "    # model_trn = model_trn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc1d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SAVE MODEL ######\n",
    "######## - 5 - ########\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Set filepath and model name\n",
    "    filepath = './'\n",
    "    model_name = 'Wonky_Doodles_CNN'\n",
    "\n",
    "    tc.save(model_trn, f\"{filepath}{model_name}.pth\")                               # Save the whole model and/or...\n",
    "    tc.save(model_trn.state_dict(), f\"{filepath}{model_name}_state_dict.pth\")       # ...save only the the model state\n",
    "\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bee210",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I'm just here so that the Screen doesn't flick when printing images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
